{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Character Sequence to Sequence \n",
    "In this notebook, we'll build a model that takes in a sequence of letters, and outputs a sorted version of that sequence. We'll do that using what we've learned so far about Sequence to Sequence models.\n",
    "\n",
    "<img src=\"images/sequence-to-sequence.jpg\"/>\n",
    "\n",
    "\n",
    "## Dataset \n",
    "\n",
    "The dataset lives in the /data/ folder. At the moment, it is made up of the following files:\n",
    " * **letters_source.txt**: The list of input letter sequences. Each sequence is its own line. \n",
    " * **letters_target.txt**: The list of target sequences we'll use in the training process. Each sequence here is a response to the input sequence in letters_source.txt with the same line number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import helper\n",
    "\n",
    "source_path = 'data/english1'\n",
    "target_path = 'data/french1'\n",
    "\n",
    "source_sentences = helper.load_data(source_path)\n",
    "target_sentences = helper.load_data(target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by examining the current state of the dataset. `source_sentences` contains the entire input sequence file as text delimited by newline symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6300181537 B000W8KY0G 1574924494 6305958041 B00077']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_sentences[:50].split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`target_sentences` contains the entire output sequence file as text delimited by newline symbols.  Each line corresponds to the line from `source_sentences`.  `target_sentences` contains a sorted characters of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B002E01LQ6 6304744404 B00008LUNW B000NQJP98 078401']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sentences[:50].split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "To do anything useful with it, we'll need to turn the characters into a list of integers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_character_vocab(data):\n",
    "    special_words = ['<pad>', '<unk>', '<s>',  '<\\s>']\n",
    "\n",
    "    set_words = set([character for line in data.split('\\n') for character in line.split(' ')])\n",
    "    int_to_vocab = {word_i: word for word_i, word in enumerate(special_words + list(set_words))}\n",
    "    vocab_to_int = {word: word_i for word_i, word in int_to_vocab.items()}\n",
    "\n",
    "    return int_to_vocab, vocab_to_int\n",
    "\n",
    "# Build int2letter and letter2int dicts\n",
    "source_int_to_letter, source_letter_to_int = extract_character_vocab(source_sentences)\n",
    "target_int_to_letter, target_letter_to_int = extract_character_vocab(target_sentences)\n",
    "\n",
    "# Convert characters to ids\n",
    "source_letter_ids = [[source_letter_to_int.get(letter, source_letter_to_int['<unk>']) for letter in line.split(' ')] for line in source_sentences.split('\\n')]\n",
    "target_letter_ids = [[target_letter_to_int.get(letter, target_letter_to_int['<unk>']) for letter in line.split(' ')] for line in target_sentences.split('\\n')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example source sequence\n",
      "[[13912, 45997, 4221, 15839, 46389, 887, 10294, 9024, 3635, 11081, 35851, 34866, 3193, 17286, 47244, 19131, 24487, 36266, 23880, 23845, 28602], [762, 20186, 49438, 3716, 3524, 42601, 27187], [12265, 50943, 32507, 1195, 28834, 32207, 46192]]\n",
      "\n",
      "\n",
      "Example target sequence\n",
      "[[50562, 31372, 28959, 19392, 35717, 25840, 25736, 5889, 40752, 42712, 29362, 42665, 48571, 17284, 33690], [10104, 48224, 52024, 32276], [7402, 50696, 24376, 20466, 17934, 45656, 25840, 11080, 28176, 39114, 29680, 28149, 32642, 48459, 40753, 20865, 47631, 3933, 8510, 39345, 5830, 40603]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Example source sequence\")\n",
    "#print(len(source_letter_to_int))\n",
    "print(source_letter_ids[:3])\n",
    "print(\"\\n\")\n",
    "print(\"Example target sequence\")\n",
    "print(target_letter_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step in the preprocessing stage is to determine the the longest sequence size in the dataset we'll be using, then pad all the sequences to that length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Length\n",
      "35\n",
      "\n",
      "\n",
      "Input sequence example\n",
      "[[13912, 45997, 4221, 15839, 46389, 887, 10294, 9024, 3635, 11081, 35851, 34866, 3193, 17286, 47244, 19131, 24487, 36266, 23880, 23845, 28602, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [762, 20186, 49438, 3716, 3524, 42601, 27187, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [12265, 50943, 32507, 1195, 28834, 32207, 46192, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "\n",
      "Target sequence example\n",
      "[[50562, 31372, 28959, 19392, 35717, 25840, 25736, 5889, 40752, 42712, 29362, 42665, 48571, 17284, 33690, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [10104, 48224, 52024, 32276, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [7402, 50696, 24376, 20466, 17934, 45656, 25840, 11080, 28176, 39114, 29680, 28149, 32642, 48459, 40753, 20865, 47631, 3933, 8510, 39345, 5830, 40603, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "def pad_id_sequences(source_ids, source_letter_to_int, target_ids, target_letter_to_int, sequence_length):\n",
    "    new_source_ids = [sentence + [source_letter_to_int['<pad>']] * (sequence_length - len(sentence)) \\\n",
    "                      for sentence in source_ids]\n",
    "    new_target_ids = [sentence + [target_letter_to_int['<pad>']] * (sequence_length - len(sentence)) \\\n",
    "                      for sentence in target_ids]\n",
    "\n",
    "    return new_source_ids, new_target_ids\n",
    "\n",
    "\n",
    "# Use the longest sequence as sequence length\n",
    "sequence_length = max(\n",
    "        [len(sentence) for sentence in source_letter_ids] + [len(sentence) for sentence in target_letter_ids])\n",
    "\n",
    "# Pad all sequences up to sequence length\n",
    "source_ids, target_ids = pad_id_sequences(source_letter_ids, source_letter_to_int, \n",
    "                                          target_letter_ids, target_letter_to_int, sequence_length)\n",
    "\n",
    "print(\"Sequence Length\")\n",
    "print(sequence_length)\n",
    "print(\"\\n\")\n",
    "print(\"Input sequence example\")\n",
    "print(source_ids[:3])\n",
    "print(\"\\n\")\n",
    "print(\"Target sequence example\")\n",
    "print(target_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final shape we need them to be in. We can now proceed to building the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "#### Check the Version of TensorFlow\n",
    "This will check to make sure you have the correct version of TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "from distutils.version import LooseVersion\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "epochs = 60\n",
    "# Batch Size\n",
    "batch_size = 128\n",
    "# RNN Size\n",
    "rnn_size = 256\n",
    "# Number of Layers\n",
    "num_layers = 2\n",
    "# Embedding Size\n",
    "encoding_embedding_size = 256\n",
    "decoding_embedding_size = 256\n",
    "# Learning Rate\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = tf.placeholder(tf.int32, [batch_size, sequence_length])\n",
    "targets = tf.placeholder(tf.int32, [batch_size, sequence_length])\n",
    "lr = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence to Sequence\n",
    "The decoder is probably the most complex part of this model. We need to declare a decoder for the training phase, and a decoder for the inference/prediction phase. These two decoders will share their parameters (so that all the weights and biases that are set during the training phase can be used when we deploy the model).\n",
    "\n",
    "\n",
    "First, we'll need to define the type of cell we'll be using for our decoder RNNs. We opted for LSTM.\n",
    "\n",
    "Then, we'll need to hookup a fully connected layer to the output of decoder. The output of this layer tells us which word the RNN is choosing to output at each time step.\n",
    "\n",
    "Let's first look at the inference/prediction decoder. It is the one we'll use when we deploy our chatbot to the wild (even though it comes second in the actual code).\n",
    "\n",
    "<img src=\"images/sequence-to-sequence-inference-decoder.png\"/>\n",
    "\n",
    "We'll hand our encoder hidden state to the inference decoder and have it process its output. TensorFlow handles most of the logic for us. We just have to use [`tf.contrib.seq2seq.simple_decoder_fn_inference`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_inference) and [`tf.contrib.seq2seq.dynamic_rnn_decoder`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder) and supply them with the appropriate inputs.\n",
    "\n",
    "Notice that the inference decoder feeds the output of each time step as an input to the next.\n",
    "\n",
    "As for the training decoder, we can think of it as looking like this:\n",
    "<img src=\"images/sequence-to-sequence-training-decoder.png\"/>\n",
    "\n",
    "The training decoder **does not** feed the output of each time step to the next. Rather, the inputs to the decoder time steps are the target sequence from the training dataset (the orange letters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "- Embed the input data using [`tf.contrib.layers.embed_sequence`](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence)\n",
    "- Pass the embedded input into a stack of RNNs.  Save the RNN state and ignore the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_vocab_size = len(source_letter_to_int)\n",
    "\n",
    "# Encoder embedding\n",
    "enc_embed_input = tf.contrib.layers.embed_sequence(input_data, source_vocab_size, encoding_embedding_size)\n",
    "\n",
    "# Encoder\n",
    "enc_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(rnn_size)] * num_layers)\n",
    "_, enc_state = tf.nn.dynamic_rnn(enc_cell, enc_embed_input, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Decoding Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets\n",
      "[[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      "  24 25 26 27 28 29 30 31 32 33 34]\n",
      " [35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58\n",
      "  59 60 61 62 63 64 65 66 67 68 69]]\n",
      "\n",
      "\n",
      "Processed Decoding Input\n",
      "[[ 2  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22\n",
      "  23 24 25 26 27 28 29 30 31 32 33]\n",
      " [ 2 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57\n",
      "  58 59 60 61 62 63 64 65 66 67 68]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Process the input we'll feed to the decoder\n",
    "ending = tf.strided_slice(targets, [0, 0], [batch_size, -1], [1, 1])\n",
    "dec_input = tf.concat([tf.fill([batch_size, 1], target_letter_to_int['<s>']), ending], 1)\n",
    "\n",
    "demonstration_outputs = np.reshape(range(batch_size * sequence_length), (batch_size, sequence_length))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "print(\"Targets\")\n",
    "print(demonstration_outputs[:2])\n",
    "print(\"\\n\")\n",
    "print(\"Processed Decoding Input\")\n",
    "print(sess.run(dec_input, {targets: demonstration_outputs})[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding\n",
    "- Embed the decoding input\n",
    "- Build the decoding RNNs\n",
    "- Build the output layer in the decoding scope, so the weight and bias can be shared between the training and inference decoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_vocab_size = len(target_letter_to_int)\n",
    "\n",
    "# Decoder Embedding\n",
    "dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoding_embedding_size]))\n",
    "dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n",
    "\n",
    "# Decoder RNNs\n",
    "dec_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(rnn_size)] * num_layers)\n",
    "\n",
    "with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "    # Output Layer\n",
    "    output_fn = lambda x: tf.contrib.layers.fully_connected(x, target_vocab_size, None, scope=decoding_scope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder During Training\n",
    "- Build the training decoder using [`tf.contrib.seq2seq.simple_decoder_fn_train`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_train) and [`tf.contrib.seq2seq.dynamic_rnn_decoder`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder).\n",
    "- Apply the output layer to the output of the training decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "    # Training Decoder\n",
    "    train_decoder_fn = tf.contrib.seq2seq.simple_decoder_fn_train(enc_state)\n",
    "    train_pred, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(\n",
    "        dec_cell, train_decoder_fn, dec_embed_input, sequence_length, scope=decoding_scope)\n",
    "    \n",
    "    # Apply output function\n",
    "    train_logits =  output_fn(train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder During Inference\n",
    "- Reuse the weights the biases from the training decoder using [`tf.variable_scope(\"decoding\", reuse=True)`](https://www.tensorflow.org/api_docs/python/tf/variable_scope)\n",
    "- Build the inference decoder using [`tf.contrib.seq2seq.simple_decoder_fn_inference`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_inference) and [`tf.contrib.seq2seq.dynamic_rnn_decoder`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder).\n",
    " - The output function is applied to the output in this step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"decoding\", reuse=True) as decoding_scope:\n",
    "    # Inference Decoder\n",
    "    infer_decoder_fn = tf.contrib.seq2seq.simple_decoder_fn_inference(\n",
    "        output_fn, enc_state, dec_embeddings, target_letter_to_int['<s>'], target_letter_to_int['<\\s>'], \n",
    "        sequence_length - 1, target_vocab_size)\n",
    "    inference_logits, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(dec_cell, infer_decoder_fn, scope=decoding_scope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "Our loss function is [`tf.contrib.seq2seq.sequence_loss`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/sequence_loss) provided by the tensor flow seq2seq module. It calculates a weighted cross-entropy loss for the output logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "cost = tf.contrib.seq2seq.sequence_loss(\n",
    "    train_logits,\n",
    "    targets,\n",
    "    tf.ones([batch_size, sequence_length]))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "# Gradient Clipping\n",
    "gradients = optimizer.compute_gradients(cost)\n",
    "capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "We're now ready to train our model. If you run into OOM (out of memory) issues during training, try to decrease the batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch    0/146 - Train Accuracy:  0.685, Validation Accuracy:  0.689, Loss: 10.889\n",
      "Epoch   0 Batch    1/146 - Train Accuracy:  0.677, Validation Accuracy:  0.689, Loss: 10.737\n",
      "Epoch   0 Batch    2/146 - Train Accuracy:  0.731, Validation Accuracy:  0.689, Loss: 10.500\n",
      "Epoch   0 Batch    3/146 - Train Accuracy:  0.700, Validation Accuracy:  0.689, Loss: 10.241\n",
      "Epoch   0 Batch    4/146 - Train Accuracy:  0.668, Validation Accuracy:  0.689, Loss:  9.987\n",
      "Epoch   0 Batch    5/146 - Train Accuracy:  0.717, Validation Accuracy:  0.689, Loss:  9.596\n",
      "Epoch   0 Batch    6/146 - Train Accuracy:  0.704, Validation Accuracy:  0.689, Loss:  9.263\n",
      "Epoch   0 Batch    7/146 - Train Accuracy:  0.706, Validation Accuracy:  0.689, Loss:  8.884\n",
      "Epoch   0 Batch    8/146 - Train Accuracy:  0.696, Validation Accuracy:  0.689, Loss:  8.488\n",
      "Epoch   0 Batch    9/146 - Train Accuracy:  0.689, Validation Accuracy:  0.689, Loss:  8.164\n",
      "Epoch   0 Batch   10/146 - Train Accuracy:  0.708, Validation Accuracy:  0.689, Loss:  7.727\n",
      "Epoch   0 Batch   11/146 - Train Accuracy:  0.744, Validation Accuracy:  0.689, Loss:  7.183\n",
      "Epoch   0 Batch   12/146 - Train Accuracy:  0.725, Validation Accuracy:  0.689, Loss:  6.921\n",
      "Epoch   0 Batch   13/146 - Train Accuracy:  0.680, Validation Accuracy:  0.689, Loss:  6.875\n",
      "Epoch   0 Batch   14/146 - Train Accuracy:  0.691, Validation Accuracy:  0.689, Loss:  6.464\n",
      "Epoch   0 Batch   15/146 - Train Accuracy:  0.688, Validation Accuracy:  0.689, Loss:  6.175\n",
      "Epoch   0 Batch   16/146 - Train Accuracy:  0.685, Validation Accuracy:  0.689, Loss:  5.901\n",
      "Epoch   0 Batch   17/146 - Train Accuracy:  0.702, Validation Accuracy:  0.689, Loss:  5.521\n",
      "Epoch   0 Batch   18/146 - Train Accuracy:  0.695, Validation Accuracy:  0.689, Loss:  5.323\n",
      "Epoch   0 Batch   19/146 - Train Accuracy:  0.665, Validation Accuracy:  0.689, Loss:  5.299\n",
      "Epoch   0 Batch   20/146 - Train Accuracy:  0.697, Validation Accuracy:  0.689, Loss:  4.720\n",
      "Epoch   0 Batch   21/146 - Train Accuracy:  0.715, Validation Accuracy:  0.689, Loss:  4.385\n",
      "Epoch   0 Batch   22/146 - Train Accuracy:  0.687, Validation Accuracy:  0.689, Loss:  4.425\n",
      "Epoch   0 Batch   23/146 - Train Accuracy:  0.703, Validation Accuracy:  0.689, Loss:  4.102\n",
      "Epoch   0 Batch   24/146 - Train Accuracy:  0.683, Validation Accuracy:  0.689, Loss:  4.174\n",
      "Epoch   0 Batch   25/146 - Train Accuracy:  0.700, Validation Accuracy:  0.689, Loss:  3.875\n",
      "Epoch   0 Batch   26/146 - Train Accuracy:  0.707, Validation Accuracy:  0.689, Loss:  3.702\n",
      "Epoch   0 Batch   27/146 - Train Accuracy:  0.711, Validation Accuracy:  0.689, Loss:  3.644\n",
      "Epoch   0 Batch   28/146 - Train Accuracy:  0.695, Validation Accuracy:  0.689, Loss:  3.827\n",
      "Epoch   0 Batch   29/146 - Train Accuracy:  0.705, Validation Accuracy:  0.689, Loss:  3.723\n",
      "Epoch   0 Batch   30/146 - Train Accuracy:  0.691, Validation Accuracy:  0.689, Loss:  3.854\n",
      "Epoch   0 Batch   31/146 - Train Accuracy:  0.692, Validation Accuracy:  0.689, Loss:  3.845\n",
      "Epoch   0 Batch   32/146 - Train Accuracy:  0.697, Validation Accuracy:  0.689, Loss:  3.812\n",
      "Epoch   0 Batch   33/146 - Train Accuracy:  0.720, Validation Accuracy:  0.689, Loss:  3.461\n",
      "Epoch   0 Batch   34/146 - Train Accuracy:  0.707, Validation Accuracy:  0.689, Loss:  3.682\n",
      "Epoch   0 Batch   35/146 - Train Accuracy:  0.695, Validation Accuracy:  0.689, Loss:  3.801\n",
      "Epoch   0 Batch   36/146 - Train Accuracy:  0.667, Validation Accuracy:  0.689, Loss:  4.197\n",
      "Epoch   0 Batch   37/146 - Train Accuracy:  0.669, Validation Accuracy:  0.689, Loss:  4.155\n",
      "Epoch   0 Batch   38/146 - Train Accuracy:  0.679, Validation Accuracy:  0.689, Loss:  3.969\n",
      "Epoch   0 Batch   39/146 - Train Accuracy:  0.656, Validation Accuracy:  0.689, Loss:  4.246\n",
      "Epoch   0 Batch   40/146 - Train Accuracy:  0.700, Validation Accuracy:  0.689, Loss:  3.701\n",
      "Epoch   0 Batch   41/146 - Train Accuracy:  0.686, Validation Accuracy:  0.689, Loss:  3.821\n",
      "Epoch   0 Batch   42/146 - Train Accuracy:  0.702, Validation Accuracy:  0.689, Loss:  3.621\n",
      "Epoch   0 Batch   43/146 - Train Accuracy:  0.718, Validation Accuracy:  0.689, Loss:  3.424\n",
      "Epoch   0 Batch   44/146 - Train Accuracy:  0.696, Validation Accuracy:  0.689, Loss:  3.722\n",
      "Epoch   0 Batch   45/146 - Train Accuracy:  0.715, Validation Accuracy:  0.689, Loss:  3.418\n",
      "Epoch   0 Batch   46/146 - Train Accuracy:  0.709, Validation Accuracy:  0.689, Loss:  3.487\n",
      "Epoch   0 Batch   47/146 - Train Accuracy:  0.726, Validation Accuracy:  0.689, Loss:  3.272\n",
      "Epoch   0 Batch   48/146 - Train Accuracy:  0.676, Validation Accuracy:  0.689, Loss:  3.897\n",
      "Epoch   0 Batch   49/146 - Train Accuracy:  0.688, Validation Accuracy:  0.689, Loss:  3.787\n",
      "Epoch   0 Batch   50/146 - Train Accuracy:  0.695, Validation Accuracy:  0.689, Loss:  3.620\n",
      "Epoch   0 Batch   51/146 - Train Accuracy:  0.691, Validation Accuracy:  0.689, Loss:  3.671\n",
      "Epoch   0 Batch   52/146 - Train Accuracy:  0.702, Validation Accuracy:  0.689, Loss:  3.547\n",
      "Epoch   0 Batch   53/146 - Train Accuracy:  0.715, Validation Accuracy:  0.689, Loss:  3.406\n",
      "Epoch   0 Batch   54/146 - Train Accuracy:  0.694, Validation Accuracy:  0.689, Loss:  3.654\n",
      "Epoch   0 Batch   55/146 - Train Accuracy:  0.716, Validation Accuracy:  0.689, Loss:  3.418\n",
      "Epoch   0 Batch   56/146 - Train Accuracy:  0.688, Validation Accuracy:  0.689, Loss:  3.725\n",
      "Epoch   0 Batch   57/146 - Train Accuracy:  0.696, Validation Accuracy:  0.689, Loss:  3.615\n",
      "Epoch   0 Batch   58/146 - Train Accuracy:  0.683, Validation Accuracy:  0.689, Loss:  3.707\n",
      "Epoch   0 Batch   59/146 - Train Accuracy:  0.721, Validation Accuracy:  0.689, Loss:  3.320\n",
      "Epoch   0 Batch   60/146 - Train Accuracy:  0.691, Validation Accuracy:  0.689, Loss:  3.665\n",
      "Epoch   0 Batch   61/146 - Train Accuracy:  0.664, Validation Accuracy:  0.689, Loss:  4.035\n",
      "Epoch   0 Batch   62/146 - Train Accuracy:  0.686, Validation Accuracy:  0.689, Loss:  3.724\n",
      "Epoch   0 Batch   63/146 - Train Accuracy:  0.709, Validation Accuracy:  0.689, Loss:  3.452\n",
      "Epoch   0 Batch   64/146 - Train Accuracy:  0.713, Validation Accuracy:  0.689, Loss:  3.377\n",
      "Epoch   0 Batch   65/146 - Train Accuracy:  0.685, Validation Accuracy:  0.689, Loss:  3.643\n",
      "Epoch   0 Batch   66/146 - Train Accuracy:  0.713, Validation Accuracy:  0.689, Loss:  3.377\n",
      "Epoch   0 Batch   67/146 - Train Accuracy:  0.693, Validation Accuracy:  0.689, Loss:  3.626\n",
      "Epoch   0 Batch   68/146 - Train Accuracy:  0.702, Validation Accuracy:  0.689, Loss:  3.483\n",
      "Epoch   0 Batch   69/146 - Train Accuracy:  0.738, Validation Accuracy:  0.689, Loss:  2.996\n",
      "Epoch   0 Batch   70/146 - Train Accuracy:  0.700, Validation Accuracy:  0.689, Loss:  3.427\n",
      "Epoch   0 Batch   71/146 - Train Accuracy:  0.709, Validation Accuracy:  0.689, Loss:  3.417\n",
      "Epoch   0 Batch   72/146 - Train Accuracy:  0.706, Validation Accuracy:  0.689, Loss:  3.432\n",
      "Epoch   0 Batch   73/146 - Train Accuracy:  0.676, Validation Accuracy:  0.689, Loss:  3.828\n",
      "Epoch   0 Batch   74/146 - Train Accuracy:  0.690, Validation Accuracy:  0.689, Loss:  3.596\n",
      "Epoch   0 Batch   75/146 - Train Accuracy:  0.687, Validation Accuracy:  0.689, Loss:  3.698\n",
      "Epoch   0 Batch   76/146 - Train Accuracy:  0.712, Validation Accuracy:  0.689, Loss:  3.368\n",
      "Epoch   0 Batch   77/146 - Train Accuracy:  0.712, Validation Accuracy:  0.689, Loss:  3.302\n",
      "Epoch   0 Batch   78/146 - Train Accuracy:  0.708, Validation Accuracy:  0.689, Loss:  3.314\n",
      "Epoch   0 Batch   79/146 - Train Accuracy:  0.681, Validation Accuracy:  0.689, Loss:  3.650\n",
      "Epoch   0 Batch   80/146 - Train Accuracy:  0.680, Validation Accuracy:  0.689, Loss:  3.674\n",
      "Epoch   0 Batch   81/146 - Train Accuracy:  0.710, Validation Accuracy:  0.689, Loss:  3.345\n",
      "Epoch   0 Batch   82/146 - Train Accuracy:  0.696, Validation Accuracy:  0.689, Loss:  3.509\n",
      "Epoch   0 Batch   83/146 - Train Accuracy:  0.718, Validation Accuracy:  0.689, Loss:  3.270\n",
      "Epoch   0 Batch   84/146 - Train Accuracy:  0.706, Validation Accuracy:  0.689, Loss:  3.327\n",
      "Epoch   0 Batch   85/146 - Train Accuracy:  0.711, Validation Accuracy:  0.689, Loss:  3.291\n",
      "Epoch   0 Batch   86/146 - Train Accuracy:  0.702, Validation Accuracy:  0.689, Loss:  3.327\n",
      "Epoch   0 Batch   87/146 - Train Accuracy:  0.712, Validation Accuracy:  0.689, Loss:  3.259\n",
      "Epoch   0 Batch   88/146 - Train Accuracy:  0.702, Validation Accuracy:  0.689, Loss:  3.358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch   89/146 - Train Accuracy:  0.719, Validation Accuracy:  0.689, Loss:  3.115\n",
      "Epoch   0 Batch   90/146 - Train Accuracy:  0.688, Validation Accuracy:  0.689, Loss:  3.530\n",
      "Epoch   0 Batch   91/146 - Train Accuracy:  0.704, Validation Accuracy:  0.689, Loss:  3.313\n",
      "Epoch   0 Batch   92/146 - Train Accuracy:  0.689, Validation Accuracy:  0.689, Loss:  3.475\n",
      "Epoch   0 Batch   93/146 - Train Accuracy:  0.654, Validation Accuracy:  0.689, Loss:  3.888\n",
      "Epoch   0 Batch   94/146 - Train Accuracy:  0.737, Validation Accuracy:  0.689, Loss:  2.939\n",
      "Epoch   0 Batch   95/146 - Train Accuracy:  0.686, Validation Accuracy:  0.689, Loss:  3.440\n",
      "Epoch   0 Batch   96/146 - Train Accuracy:  0.710, Validation Accuracy:  0.689, Loss:  3.248\n",
      "Epoch   0 Batch   97/146 - Train Accuracy:  0.685, Validation Accuracy:  0.689, Loss:  3.490\n",
      "Epoch   0 Batch   98/146 - Train Accuracy:  0.677, Validation Accuracy:  0.689, Loss:  3.579\n",
      "Epoch   0 Batch   99/146 - Train Accuracy:  0.704, Validation Accuracy:  0.689, Loss:  3.296\n",
      "Epoch   0 Batch  100/146 - Train Accuracy:  0.696, Validation Accuracy:  0.689, Loss:  3.311\n",
      "Epoch   0 Batch  101/146 - Train Accuracy:  0.693, Validation Accuracy:  0.689, Loss:  3.428\n",
      "Epoch   0 Batch  102/146 - Train Accuracy:  0.710, Validation Accuracy:  0.689, Loss:  3.209\n",
      "Epoch   0 Batch  103/146 - Train Accuracy:  0.691, Validation Accuracy:  0.689, Loss:  3.423\n",
      "Epoch   0 Batch  104/146 - Train Accuracy:  0.668, Validation Accuracy:  0.689, Loss:  3.618\n",
      "Epoch   0 Batch  105/146 - Train Accuracy:  0.708, Validation Accuracy:  0.689, Loss:  3.153\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-29d5072a99c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         batch_train_logits = sess.run(\n\u001b[1;32m     18\u001b[0m             \u001b[0minference_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             {input_data: source_batch})\n\u001b[0m\u001b[1;32m     20\u001b[0m         batch_valid_logits = sess.run(\n\u001b[1;32m     21\u001b[0m             \u001b[0minference_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m//anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_source = source_ids[batch_size:]\n",
    "train_target = target_ids[batch_size:]\n",
    "\n",
    "valid_source = source_ids[:batch_size]\n",
    "valid_target = target_ids[:batch_size]\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch_i in range(epochs):\n",
    "    for batch_i, (source_batch, target_batch) in enumerate(\n",
    "            helper.batch_data(train_source, train_target, batch_size)):\n",
    "        _, loss = sess.run(\n",
    "            [train_op, cost],\n",
    "            {input_data: source_batch, targets: target_batch, lr: learning_rate})\n",
    "        batch_train_logits = sess.run(\n",
    "            inference_logits,\n",
    "            {input_data: source_batch})\n",
    "        batch_valid_logits = sess.run(\n",
    "            inference_logits,\n",
    "            {input_data: valid_source})\n",
    "\n",
    "        train_acc = np.mean(np.equal(target_batch, np.argmax(batch_train_logits, 2)))\n",
    "        valid_acc = np.mean(np.equal(valid_target, np.argmax(batch_valid_logits, 2)))\n",
    "        print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.3f}, Validation Accuracy: {:>6.3f}, Loss: {:>6.3f}'\n",
    "              .format(epoch_i, batch_i, len(source_ids) // batch_size, train_acc, valid_acc, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "  Word Ids:      [20, 18, 28, 28, 10, 0, 0]\n",
      "  Input Words: ['h', 'e', 'l', 'l', 'o', '<pad>', '<pad>']\n",
      "\n",
      "Prediction\n",
      "  Word Ids:      [18, 20, 28, 28, 10, 0, 0]\n",
      "  Chatbot Answer Words: ['e', 'h', 'l', 'l', 'o', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "input_sentence = 'hello'\n",
    "\n",
    "\n",
    "input_sentence = [source_letter_to_int.get(word, source_letter_to_int['<unk>']) for word in input_sentence.lower()]\n",
    "input_sentence = input_sentence + [0] * (sequence_length - len(input_sentence))\n",
    "batch_shell = np.zeros((batch_size, sequence_length))\n",
    "batch_shell[0] = input_sentence\n",
    "chatbot_logits = sess.run(inference_logits, {input_data: batch_shell})[0]\n",
    "\n",
    "print('Input')\n",
    "print('  Word Ids:      {}'.format([i for i in input_sentence]))\n",
    "print('  Input Words: {}'.format([source_int_to_letter[i] for i in input_sentence]))\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('  Word Ids:      {}'.format([i for i in np.argmax(chatbot_logits, 1)]))\n",
    "print('  Chatbot Answer Words: {}'.format([target_int_to_letter[i] for i in np.argmax(chatbot_logits, 1)]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
